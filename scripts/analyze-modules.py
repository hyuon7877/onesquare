#!/usr/bin/env python3
"""
OneSquare ëª¨ë“ˆ ë¶„ì„ ë„êµ¬
ëª¨ë“ˆ ê°„ ì¤‘ë³µ, ë³µì¡ë„, ì˜ì¡´ì„±ì„ ë¶„ì„í•˜ê³  ë¦¬íŒ©í† ë§ ì œì•ˆ
"""

import os
import ast
import re
import json
from pathlib import Path
from datetime import datetime
from collections import defaultdict, Counter
import difflib

class ModuleAnalyzer:
    def __init__(self):
        self.project_root = Path(__file__).parent.parent
        self.src_path = self.project_root / "src"
        self.apps_path = self.src_path / "apps"
        self.analysis_results = {
            'similar_modules': [],
            'duplicate_dependencies': {},
            'complexity_scores': {},
            'refactoring_suggestions': [],
            'statistics': {}
        }
        
    def print_header(self):
        """í—¤ë” ì¶œë ¥"""
        print("\n" + "="*60)
        print("ğŸ” OneSquare ëª¨ë“ˆ ë¶„ì„ ë„êµ¬")
        print("="*60)
        
    def analyze_python_file(self, file_path):
        """Python íŒŒì¼ ë¶„ì„"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                tree = ast.parse(content)
                
            return {
                'path': str(file_path),
                'content': content,
                'tree': tree,
                'imports': self.extract_imports(tree),
                'classes': self.extract_classes(tree),
                'functions': self.extract_functions(tree),
                'complexity': self.calculate_complexity(tree),
                'lines': len(content.splitlines()),
                'docstrings': self.extract_docstrings(tree)
            }
        except Exception as e:
            return None
            
    def extract_imports(self, tree):
        """import ë¬¸ ì¶”ì¶œ"""
        imports = []
        for node in ast.walk(tree):
            if isinstance(node, ast.Import):
                for alias in node.names:
                    imports.append(alias.name)
            elif isinstance(node, ast.ImportFrom):
                module = node.module or ''
                for alias in node.names:
                    imports.append(f"{module}.{alias.name}" if module else alias.name)
        return imports
        
    def extract_classes(self, tree):
        """í´ë˜ìŠ¤ ì •ë³´ ì¶”ì¶œ"""
        classes = []
        for node in ast.walk(tree):
            if isinstance(node, ast.ClassDef):
                methods = [n.name for n in node.body if isinstance(n, ast.FunctionDef)]
                classes.append({
                    'name': node.name,
                    'methods': methods,
                    'lines': node.end_lineno - node.lineno + 1 if hasattr(node, 'end_lineno') else 0
                })
        return classes
        
    def extract_functions(self, tree):
        """í•¨ìˆ˜ ì •ë³´ ì¶”ì¶œ"""
        functions = []
        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef) and not isinstance(node, ast.AsyncFunctionDef):
                # í´ë˜ìŠ¤ ë©”ì„œë“œê°€ ì•„ë‹Œ ê²½ìš°ë§Œ
                parent = self.get_parent_class(tree, node)
                if not parent:
                    functions.append({
                        'name': node.name,
                        'args': len(node.args.args),
                        'lines': node.end_lineno - node.lineno + 1 if hasattr(node, 'end_lineno') else 0
                    })
        return functions
        
    def get_parent_class(self, tree, node):
        """ë…¸ë“œì˜ ë¶€ëª¨ í´ë˜ìŠ¤ ì°¾ê¸°"""
        for cls in ast.walk(tree):
            if isinstance(cls, ast.ClassDef):
                for item in cls.body:
                    if item == node:
                        return cls
        return None
        
    def calculate_complexity(self, tree):
        """Cyclomatic Complexity ê³„ì‚°"""
        complexity = 1  # ê¸°ë³¸ ë³µì¡ë„
        
        for node in ast.walk(tree):
            if isinstance(node, (ast.If, ast.While, ast.For, ast.ExceptHandler)):
                complexity += 1
            elif isinstance(node, ast.BoolOp):
                complexity += len(node.values) - 1
                
        return complexity
        
    def extract_docstrings(self, tree):
        """docstring ì¶”ì¶œ"""
        docstrings = []
        for node in ast.walk(tree):
            if isinstance(node, (ast.FunctionDef, ast.ClassDef, ast.Module)):
                docstring = ast.get_docstring(node)
                if docstring:
                    docstrings.append(docstring[:100])  # ì²˜ìŒ 100ìë§Œ
        return docstrings
        
    def find_similar_modules(self, modules):
        """ë¹„ìŠ·í•œ ëª¨ë“ˆ ì°¾ê¸°"""
        print("\nğŸ“Š ë¹„ìŠ·í•œ ê¸°ëŠ¥ì˜ ëª¨ë“ˆ ê°ì§€ ì¤‘...")
        similar_pairs = []
        
        for i, mod1 in enumerate(modules):
            for mod2 in modules[i+1:]:
                # í•¨ìˆ˜/í´ë˜ìŠ¤ ì´ë¦„ ë¹„êµ
                funcs1 = set([f['name'] for f in mod1.get('functions', [])])
                funcs2 = set([f['name'] for f in mod2.get('functions', [])])
                classes1 = set([c['name'] for c in mod1.get('classes', [])])
                classes2 = set([c['name'] for c in mod2.get('classes', [])])
                
                # ìœ ì‚¬ë„ ê³„ì‚°
                func_similarity = len(funcs1 & funcs2) / max(len(funcs1 | funcs2), 1)
                class_similarity = len(classes1 & classes2) / max(len(classes1 | classes2), 1)
                
                # ì½”ë“œ ìœ ì‚¬ë„ (ê°„ë‹¨í•œ ë²„ì „)
                if mod1.get('content') and mod2.get('content'):
                    seq = difflib.SequenceMatcher(None, 
                                                 mod1['content'][:1000], 
                                                 mod2['content'][:1000])
                    content_similarity = seq.ratio()
                else:
                    content_similarity = 0
                    
                total_similarity = (func_similarity + class_similarity + content_similarity) / 3
                
                if total_similarity > 0.3:  # 30% ì´ìƒ ìœ ì‚¬
                    similar_pairs.append({
                        'module1': Path(mod1['path']).name,
                        'module2': Path(mod2['path']).name,
                        'similarity': round(total_similarity * 100, 1),
                        'shared_functions': list(funcs1 & funcs2),
                        'shared_classes': list(classes1 & classes2)
                    })
                    
        return similar_pairs
        
    def find_duplicate_dependencies(self, modules):
        """ì¤‘ë³µ ì˜ì¡´ì„± ì°¾ê¸°"""
        print("\nğŸ”— ì¤‘ë³µ ì˜ì¡´ì„± ë¶„ì„ ì¤‘...")
        
        # ëª¨ë“  import ìˆ˜ì§‘
        import_counter = Counter()
        module_imports = defaultdict(list)
        
        for mod in modules:
            if mod and 'imports' in mod:
                mod_name = Path(mod['path']).stem
                for imp in mod['imports']:
                    import_counter[imp] += 1
                    module_imports[imp].append(mod_name)
                    
        # 2ê°œ ì´ìƒì˜ ëª¨ë“ˆì—ì„œ ì‚¬ìš©í•˜ëŠ” import
        duplicates = {}
        for imp, count in import_counter.items():
            if count >= 2 and not imp.startswith('django'):  # Django ê¸°ë³¸ ì œì™¸
                duplicates[imp] = {
                    'count': count,
                    'modules': module_imports[imp]
                }
                
        return duplicates
        
    def analyze_complexity(self, modules):
        """ëª¨ë“ˆ ë³µì¡ë„ ë¶„ì„"""
        print("\nğŸ“ˆ ëª¨ë“ˆ ë³µì¡ë„ ë¶„ì„ ì¤‘...")
        
        complexity_data = {}
        
        for mod in modules:
            if mod:
                mod_name = Path(mod['path']).stem
                
                # ë³µì¡ë„ ì ìˆ˜ ê³„ì‚°
                score = 0
                details = []
                
                # Cyclomatic Complexity
                cc = mod.get('complexity', 0)
                if cc > 10:
                    score += (cc - 10) * 2
                    details.append(f"ë†’ì€ ìˆœí™˜ ë³µì¡ë„: {cc}")
                    
                # íŒŒì¼ ê¸¸ì´
                lines = mod.get('lines', 0)
                if lines > 200:
                    score += (lines - 200) / 50
                    details.append(f"ê¸´ íŒŒì¼: {lines}ì¤„")
                    
                # í´ë˜ìŠ¤/í•¨ìˆ˜ ìˆ˜
                num_classes = len(mod.get('classes', []))
                num_functions = len(mod.get('functions', []))
                
                if num_classes > 3:
                    score += (num_classes - 3) * 3
                    details.append(f"ë§ì€ í´ë˜ìŠ¤: {num_classes}ê°œ")
                    
                if num_functions > 10:
                    score += (num_functions - 10)
                    details.append(f"ë§ì€ í•¨ìˆ˜: {num_functions}ê°œ")
                    
                # Docstring ë¶€ì¡±
                if not mod.get('docstrings'):
                    score += 5
                    details.append("ë¬¸ì„œí™” ë¶€ì¡±")
                    
                complexity_data[mod_name] = {
                    'score': round(score, 1),
                    'level': self.get_complexity_level(score),
                    'details': details,
                    'metrics': {
                        'cyclomatic': cc,
                        'lines': lines,
                        'classes': num_classes,
                        'functions': num_functions,
                        'imports': len(mod.get('imports', []))
                    }
                }
                
        return complexity_data
        
    def get_complexity_level(self, score):
        """ë³µì¡ë„ ë ˆë²¨ ê²°ì •"""
        if score < 5:
            return "ë‚®ìŒ ğŸŸ¢"
        elif score < 15:
            return "ë³´í†µ ğŸŸ¡"
        elif score < 30:
            return "ë†’ìŒ ğŸŸ "
        else:
            return "ë§¤ìš° ë†’ìŒ ğŸ”´"
            
    def generate_refactoring_suggestions(self):
        """ë¦¬íŒ©í† ë§ ì œì•ˆ ìƒì„±"""
        suggestions = []
        
        # ë¹„ìŠ·í•œ ëª¨ë“ˆ ë³‘í•© ì œì•ˆ
        if self.analysis_results['similar_modules']:
            for similar in self.analysis_results['similar_modules']:
                if similar['similarity'] > 50:
                    suggestions.append({
                        'type': 'ëª¨ë“ˆ ë³‘í•©',
                        'priority': 'ë†’ìŒ',
                        'modules': [similar['module1'], similar['module2']],
                        'reason': f"{similar['similarity']}% ìœ ì‚¬ë„",
                        'action': f"{similar['module1']}ê³¼ {similar['module2']}ë¥¼ í•˜ë‚˜ì˜ ëª¨ë“ˆë¡œ í†µí•© ê²€í† "
                    })
                    
        # ë³µì¡ë„ ê¸°ë°˜ ì œì•ˆ
        for mod_name, complexity in self.analysis_results['complexity_scores'].items():
            if complexity['score'] > 20:
                suggestions.append({
                    'type': 'ëª¨ë“ˆ ë¶„í• ',
                    'priority': 'ë†’ìŒ' if complexity['score'] > 30 else 'ì¤‘ê°„',
                    'modules': [mod_name],
                    'reason': f"ë³µì¡ë„ ì ìˆ˜ {complexity['score']}",
                    'action': f"{mod_name} ëª¨ë“ˆì„ ì‘ì€ ë‹¨ìœ„ë¡œ ë¶„í• "
                })
                
        # ì¤‘ë³µ ì˜ì¡´ì„± ì œì•ˆ
        for dep, info in self.analysis_results['duplicate_dependencies'].items():
            if info['count'] >= 3:
                suggestions.append({
                    'type': 'ê³µí†µ ëª¨ë“ˆí™”',
                    'priority': 'ì¤‘ê°„',
                    'modules': info['modules'],
                    'reason': f"{dep}ë¥¼ {info['count']}ê°œ ëª¨ë“ˆì—ì„œ ì‚¬ìš©",
                    'action': f"{dep} ê´€ë ¨ ê¸°ëŠ¥ì„ ê³µí†µ ìœ í‹¸ë¦¬í‹°ë¡œ ì¶”ì¶œ"
                })
                
        return suggestions
        
    def generate_report(self):
        """ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        report = []
        report.append("\n" + "="*60)
        report.append("ğŸ“Š OneSquare ëª¨ë“ˆ ë¶„ì„ ë¦¬í¬íŠ¸")
        report.append(f"ğŸ“… ìƒì„± ì‹œê°„: {timestamp}")
        report.append("="*60)
        
        # 1. í†µê³„
        report.append("\n## ğŸ“ˆ ì „ì²´ í†µê³„")
        report.append(f"- ë¶„ì„ëœ ëª¨ë“ˆ: {self.analysis_results['statistics'].get('total_modules', 0)}ê°œ")
        report.append(f"- ì´ ì½”ë“œ ë¼ì¸: {self.analysis_results['statistics'].get('total_lines', 0):,}ì¤„")
        report.append(f"- í‰ê·  ë³µì¡ë„: {self.analysis_results['statistics'].get('avg_complexity', 0):.1f}")
        
        # 2. ë¹„ìŠ·í•œ ëª¨ë“ˆ
        if self.analysis_results['similar_modules']:
            report.append("\n## ğŸ”„ ë¹„ìŠ·í•œ ëª¨ë“ˆ")
            for similar in sorted(self.analysis_results['similar_modules'], 
                                 key=lambda x: x['similarity'], reverse=True)[:5]:
                report.append(f"- {similar['module1']} â†” {similar['module2']}: "
                            f"{similar['similarity']}% ìœ ì‚¬")
                if similar['shared_functions']:
                    report.append(f"  ê³µí†µ í•¨ìˆ˜: {', '.join(similar['shared_functions'][:3])}")
                    
        # 3. ë³µì¡ë„ ë†’ì€ ëª¨ë“ˆ
        report.append("\n## ğŸ”´ ë³µì¡ë„ ë†’ì€ ëª¨ë“ˆ (ìƒìœ„ 5ê°œ)")
        complex_modules = sorted(self.analysis_results['complexity_scores'].items(),
                                key=lambda x: x[1]['score'], reverse=True)[:5]
        for mod_name, complexity in complex_modules:
            report.append(f"- {mod_name}: {complexity['level']} (ì ìˆ˜: {complexity['score']})")
            for detail in complexity['details'][:2]:
                report.append(f"  â€¢ {detail}")
                
        # 4. ì¤‘ë³µ ì˜ì¡´ì„±
        if self.analysis_results['duplicate_dependencies']:
            report.append("\n## ğŸ”— ì¤‘ë³µ ì˜ì¡´ì„± (ìƒìœ„ 5ê°œ)")
            sorted_deps = sorted(self.analysis_results['duplicate_dependencies'].items(),
                               key=lambda x: x[1]['count'], reverse=True)[:5]
            for dep, info in sorted_deps:
                report.append(f"- {dep}: {info['count']}ê°œ ëª¨ë“ˆì—ì„œ ì‚¬ìš©")
                report.append(f"  ì‚¬ìš© ëª¨ë“ˆ: {', '.join(info['modules'][:4])}")
                
        # 5. ë¦¬íŒ©í† ë§ ì œì•ˆ
        report.append("\n## ğŸ’¡ ë¦¬íŒ©í† ë§ ì œì•ˆ")
        suggestions = self.generate_refactoring_suggestions()
        self.analysis_results['refactoring_suggestions'] = suggestions
        
        high_priority = [s for s in suggestions if s['priority'] == 'ë†’ìŒ']
        medium_priority = [s for s in suggestions if s['priority'] == 'ì¤‘ê°„']
        
        if high_priority:
            report.append("\n### ğŸ”´ ë†’ì€ ìš°ì„ ìˆœìœ„")
            for sug in high_priority[:3]:
                report.append(f"- [{sug['type']}] {sug['action']}")
                report.append(f"  ì´ìœ : {sug['reason']}")
                
        if medium_priority:
            report.append("\n### ğŸŸ¡ ì¤‘ê°„ ìš°ì„ ìˆœìœ„")
            for sug in medium_priority[:3]:
                report.append(f"- [{sug['type']}] {sug['action']}")
                report.append(f"  ì´ìœ : {sug['reason']}")
                
        # 6. ê±´ê°•ë„ ì ìˆ˜
        health_score = self.calculate_health_score()
        report.append(f"\n## ğŸ¥ ì „ì²´ ëª¨ë“ˆ ê±´ê°•ë„: {health_score}/100")
        
        if health_score >= 80:
            report.append("âœ… ìš°ìˆ˜í•œ ìƒíƒœì…ë‹ˆë‹¤!")
        elif health_score >= 60:
            report.append("ğŸŸ¡ ê°œì„ ì´ í•„ìš”í•œ ë¶€ë¶„ì´ ìˆìŠµë‹ˆë‹¤.")
        else:
            report.append("ğŸ”´ ë¦¬íŒ©í† ë§ì´ ì‹œê¸‰í•©ë‹ˆë‹¤.")
            
        report.append("\n" + "="*60)
        
        return '\n'.join(report)
        
    def calculate_health_score(self):
        """ì „ì²´ ê±´ê°•ë„ ì ìˆ˜ ê³„ì‚°"""
        score = 100
        
        # ë¹„ìŠ·í•œ ëª¨ë“ˆ ê°ì 
        similar_count = len(self.analysis_results['similar_modules'])
        score -= min(similar_count * 3, 20)
        
        # ë†’ì€ ë³µì¡ë„ ê°ì 
        high_complexity = sum(1 for _, c in self.analysis_results['complexity_scores'].items()
                            if c['score'] > 20)
        score -= min(high_complexity * 5, 30)
        
        # ì¤‘ë³µ ì˜ì¡´ì„± ê°ì 
        dup_deps = len(self.analysis_results['duplicate_dependencies'])
        score -= min(dup_deps * 2, 20)
        
        return max(score, 0)
        
    def save_report(self, report):
        """ë¦¬í¬íŠ¸ ì €ì¥"""
        report_dir = self.project_root / "docs" / "analysis"
        report_dir.mkdir(parents=True, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = report_dir / f"module_analysis_{timestamp}.md"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)
            
        # JSON í˜•ì‹ìœ¼ë¡œë„ ì €ì¥
        json_file = report_dir / f"module_analysis_{timestamp}.json"
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(self.analysis_results, f, ensure_ascii=False, indent=2, default=str)
            
        return report_file, json_file
        
    def run(self):
        """ë©”ì¸ ì‹¤í–‰"""
        self.print_header()
        
        # ëª¨ë“  Python íŒŒì¼ ìˆ˜ì§‘
        print("\nğŸ“‚ Python ëª¨ë“ˆ ìˆ˜ì§‘ ì¤‘...")
        python_files = list(self.apps_path.rglob("*.py"))
        
        # __pycache__ ë° migrations ì œì™¸
        python_files = [f for f in python_files 
                       if '__pycache__' not in str(f) 
                       and 'migrations' not in str(f)
                       and '__init__.py' not in f.name]
        
        print(f"  {len(python_files)}ê°œ íŒŒì¼ ë°œê²¬")
        
        # ê° íŒŒì¼ ë¶„ì„
        print("\nğŸ” ëª¨ë“ˆ ë¶„ì„ ì¤‘...")
        modules = []
        total_lines = 0
        total_complexity = 0
        
        for file_path in python_files:
            module = self.analyze_python_file(file_path)
            if module:
                modules.append(module)
                total_lines += module.get('lines', 0)
                total_complexity += module.get('complexity', 0)
                print(f"  âœ“ {file_path.name}")
                
        # í†µê³„ ì €ì¥
        self.analysis_results['statistics'] = {
            'total_modules': len(modules),
            'total_lines': total_lines,
            'avg_complexity': total_complexity / max(len(modules), 1)
        }
        
        # ë¶„ì„ ìˆ˜í–‰
        self.analysis_results['similar_modules'] = self.find_similar_modules(modules)
        self.analysis_results['duplicate_dependencies'] = self.find_duplicate_dependencies(modules)
        self.analysis_results['complexity_scores'] = self.analyze_complexity(modules)
        
        # ë¦¬í¬íŠ¸ ìƒì„±
        report = self.generate_report()
        
        # ë¦¬í¬íŠ¸ ì¶œë ¥
        print(report)
        
        # ë¦¬í¬íŠ¸ ì €ì¥
        md_file, json_file = self.save_report(report)
        print(f"\nğŸ“„ ë¦¬í¬íŠ¸ ì €ì¥ë¨:")
        print(f"  - Markdown: {md_file}")
        print(f"  - JSON: {json_file}")
        
        print("\nâœ¨ ë¶„ì„ ì™„ë£Œ!")

def main():
    """ì§„ì…ì """
    analyzer = ModuleAnalyzer()
    analyzer.run()

if __name__ == "__main__":
    main()